{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Chtv4M5LW_A"
      },
      "source": [
        "# Garbage Classification using PyTorch\n",
        "\n",
        "Garbage segregation involves separating wastes according to how it's handled or processed. It's important for recycling as some materials are recyclable and others are not.\n",
        "\n",
        "\n",
        "![Garbage Bins](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwebstockreview.net%2Fimages%2Fgarbage-clipart-wastebin-16.png&f=1&nofb=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_RfZdDiLW_E"
      },
      "source": [
        "Let us start by importing the libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3fvP77HLW_E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import random_split\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu4M9Z7ZLW_F"
      },
      "source": [
        "Let us see the classes present in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFm_cWH7NiL9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boLVPXdGLW_G"
      },
      "outputs": [],
      "source": [
        "path = 'INSERT_GOOGLE_DRIVE_OF_DATA'\n",
        "data_dir  = path\n",
        "\n",
        "classes = os.listdir(data_dir)\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7dh3kZtLW_H"
      },
      "source": [
        "## Transformations:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYg_ET40LW_H"
      },
      "source": [
        "Now, let's apply transformations to the dataset and import it for use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IMQlrxvLW_H"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transformations = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
        "\n",
        "dataset = ImageFolder(data_dir, transform = transformations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okLSeH8sOR3A"
      },
      "outputs": [],
      "source": [
        "#dataset = ImageFolder(data_dir, transform = transformations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-35JiEucLW_I"
      },
      "source": [
        "Let's create a helper function to see the image and its corresponding label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szNUvWf5LW_I"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_sample(img, label):\n",
        "    print(\"Label:\", dataset.classes[label], \"(Class No: \"+ str(label) + \")\")\n",
        "    plt.imshow(img.permute(1, 2, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVQnfcgeLW_J"
      },
      "outputs": [],
      "source": [
        "img, label = dataset[12]\n",
        "show_sample(img, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxSChh2tLW_J"
      },
      "source": [
        "# Loading and Splitting Data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUztsm24LW_J"
      },
      "outputs": [],
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggaA0HgrLW_J"
      },
      "source": [
        "We'll split the dataset into training, validation and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb_-X7SCmebV"
      },
      "outputs": [],
      "source": [
        "''' OPTIONAL\n",
        "def split3(dataset, ratio=[0.7, 0.2, 0.1]):\n",
        "  import numpy as np #import library\n",
        "  train_r, val_r, test_r = ratio #assign ratio variables to train/val/test\n",
        "  indSplit = [int(len(dataset)*train_r), int(len(dataset)*(train_r+val_r))] #identify index to split\n",
        "  train, val, test = np.split(dataset, indSplit) #split dataset at indices\n",
        "  return train, val, test #return split data as train val and test data\n",
        "\n",
        "train_ds, val_ds, test_ds = split3(dataset=dataset, ratio=[0.8, 0.1, 0.1]) #split data into specified ratio\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mija4SzILW_J"
      },
      "outputs": [],
      "source": [
        "train_ds, val_ds, test_ds = random_split(dataset, [0.7, 0.2, 0.1])\n",
        "len(train_ds), len(val_ds), len(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieGaxG5VLW_K"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-XzpG_7LW_K"
      },
      "source": [
        "Now, we'll create training and validation dataloaders using `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOCKzGSlLW_K"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 4, pin_memory = True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2, num_workers = 4, pin_memory = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKprlMOsLW_K"
      },
      "source": [
        "This is a helper function to visualize batches:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H8CGgrGLW_K"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow = 16).permute(1, 2, 0))\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "057bCiF8LW_K"
      },
      "outputs": [],
      "source": [
        "show_batch(train_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8R6Ejk1LW_L"
      },
      "source": [
        "# Model Base:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnJpTgFALW_L"
      },
      "source": [
        "Let's create the model base:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnhI7DhRLW_L"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch {}: train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch+1, result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl5P4H2kLW_L"
      },
      "source": [
        "We'll be using ResNet50 for classifying images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68T4ClcYLW_L"
      },
      "outputs": [],
      "source": [
        "class ResNet(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Use a pretrained model\n",
        "        self.network = models.resnet50(pretrained=True)\n",
        "        # Replace last layer\n",
        "        num_ftrs = self.network.fc.in_features\n",
        "        self.network.fc = nn.Linear(num_ftrs, len(dataset.classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return torch.sigmoid(self.network(xb))\n",
        "\n",
        "model = ResNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vokPzR-sLW_L"
      },
      "source": [
        "## Porting to GPU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUNxSnicLW_M"
      },
      "source": [
        "GPUs tend to perform faster calculations than CPU. Let's take this advantage and use GPU for computation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST4OZfwVLW_M"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1BVt710Fnr6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoRhPMh2LW_M"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zieBQ0XjLW_M"
      },
      "outputs": [],
      "source": [
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hMupVMLLW_M"
      },
      "source": [
        "# Training the Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ste1Ua1GLW_M"
      },
      "source": [
        "This is the function for fitting the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3B4ARAILW_M"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqfZZUF1LW_N"
      },
      "outputs": [],
      "source": [
        "model = to_device(ResNet(), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_bAIW4CLW_N"
      },
      "outputs": [],
      "source": [
        "evaluate(model, val_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXEWyfrNLW_N"
      },
      "source": [
        "Let's start training the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yBiCE_MgLW_N"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 5.5e-6\n",
        "\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z8hVOs0ALW_N"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LLd1-ZSgLW_S"
      },
      "outputs": [],
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0m9cvs6LW_S"
      },
      "source": [
        "# Visualizing Predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DXoNBjBELW_S"
      },
      "outputs": [],
      "source": [
        "def predict_image(img, model):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model(xb)\n",
        "    # Pick index with highest probability\n",
        "    prob, preds  = torch.max(yb, dim=1)\n",
        "    # Retrieve the class label\n",
        "    return dataset.classes[preds[0].item()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sccbt65vLW_S"
      },
      "source": [
        "Let us see the model's predictions on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I779struLW_S"
      },
      "outputs": [],
      "source": [
        "img, label = test_ds[17]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ivV3I5Z9LW_T"
      },
      "outputs": [],
      "source": [
        "img, label = test_ds[23]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VajWTk7ILW_T"
      },
      "outputs": [],
      "source": [
        "img, label = test_ds[51]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QRQayFWLW_T"
      },
      "source": [
        "# Predicting External Images:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j01S3Y1YLW_T"
      },
      "source": [
        "Let's now test with external images.\n",
        "\n",
        "I'll use `urllib` for downloading external images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOy8Fr1yLW_T"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "url = input(\"Enter a url\")\n",
        "\n",
        "urllib.request.urlretrieve(url, \"external_photo.jpg\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47-lPqx5LW_U"
      },
      "source": [
        "Let us load the model. You can load an external pre-trained model too!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTZfsbMYLW_U"
      },
      "outputs": [],
      "source": [
        "loaded_model = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvtNZn55LW_U"
      },
      "source": [
        "This function takes the image's name and prints the predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmCq9FVWLW_U"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "def predict_external_image(image_name):\n",
        "    image = Image.open(Path('./' + image_name))\n",
        "\n",
        "    example_image = transformations(image)\n",
        "    plt.imshow(example_image.permute(1, 2, 0))\n",
        "    print(\"The image resembles\", predict_image(example_image, loaded_model) + \".\")\n",
        "\n",
        "predict_external_image('external_photo.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t1w-qElTSbD"
      },
      "source": [
        "Now let's allow users to use their webcams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oDsF5BPLW_U"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import io\n",
        "import html\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFF73-CJTqfw"
      },
      "source": [
        "Helper functions to make converting between different image data types and formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRi_5GQFLW_V"
      },
      "outputs": [],
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW714C_BT8N-"
      },
      "source": [
        "We will be using the code snippet for Camera Capture to utilize your computer's webcam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XomQ82I0LW_V"
      },
      "outputs": [],
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data)\n",
        "  # grayscale img\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  print(gray.shape)\n",
        "\n",
        "  cv2.imwrite(filename, img)\n",
        "\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Trt9FzdLLW_V"
      },
      "outputs": [],
      "source": [
        "\n",
        "try:\n",
        "  filename = take_photo('photo.jpg')\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "  # Open and display the image which was just taken.\n",
        "  img = PIL.Image.open(filename)\n",
        "  #img.show()\n",
        "  display(img)\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERFravlTUyao"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "def predict_external_image(image_name):\n",
        "    image = Image.open(image_name)\n",
        "\n",
        "    # Convert PIL Image to PyTorch tensor\n",
        "    transformations = torchvision.transforms.ToTensor()\n",
        "    example_image = transformations(image)\n",
        "\n",
        "    plt.imshow(example_image.permute(1, 2, 0))\n",
        "    print(\"The image resembles\", predict_image(example_image, loaded_model) + \".\")\n",
        "\n",
        "# Call the function with 'photo.jpg' as an argument\n",
        "predict_external_image(\"photo.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ6enM8DLW_V"
      },
      "source": [
        "# Conclusion:\n",
        "\n",
        "Our model was able to classify garbage with **94% accuracy**!\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}